{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing experiments for HOTA evaluation\n",
    "\n",
    "In this script, we are mainly moving data into the right directory and format, for HOTA evaluation. Unfortunately this is currently only possible within the [TrackEval](https://github.com/JonathonLuiten/TrackEval/) package.\n",
    "\n",
    "Ideally the data is in the following structure.\n",
    "\n",
    "gt_folder \n",
    "   |-------Vid1\n",
    "            |-----labels_with_ids\n",
    "                    |------frame_000000.txt\n",
    "                    |------frame_000001.txt\n",
    "   |------Vid2...\n",
    "\n",
    "\n",
    "pred_folder\n",
    "   |------Vid1\n",
    "           |------model1\n",
    "                    |------results.txt\n",
    "           |------model2\n",
    "                    |------results.txt\n",
    "        ...\n",
    "   |------Vid2...\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_files_to_dict(folder_path, scale_size = (1920, 1080)):\n",
    "    '''\n",
    "    input: path to a video, to the folder which contains the label files (in the format that there is \n",
    "    one label file per frame)\n",
    "    output: dictionary containing all the frames and bboxes\n",
    "    '''\n",
    "    width, height = scale_size\n",
    "    data_names = os.listdir(folder_path)\n",
    "    data_names = [name for name in data_names if re.search(\".txt\",name)]\n",
    "    frame_nr = []\n",
    "    class_name = []\n",
    "    id_nr = []\n",
    "    bbox_xywh = []\n",
    "    for data_name in data_names:\n",
    "        maca_data = open(os.path.join(folder_path,data_name)).read().strip().split(\"\\n\")\n",
    "        if maca_data == [\"\"]:\n",
    "            continue\n",
    "        maca_data = [[float(nr) for nr in row.strip().split(\" \")] for row in maca_data]\n",
    "        frame_name = data_name.split(\".\")[0]\n",
    "        #-1 that mot also starts at 0\n",
    "        frame_nr_to_append = int(re.findall(\"[0-9]+\",frame_name)[0])\n",
    "        for row in maca_data:\n",
    "            frame_nr.append(frame_nr_to_append)\n",
    "            class_name.append(row[0])\n",
    "            id_nr.append(row[1])\n",
    "            #to upper left corner from middle \n",
    "            row[2] = (float(row[2]) - float(row[4])/2) * width\n",
    "            row[3] = (float(row[3]) - float(row[5])/2) * height\n",
    "            row[4] = float(row[4]) * width\n",
    "            row[5] = float(row[5]) * height\n",
    "            row[2:6] = [round(x,2) for x in row[2:6]]\n",
    "            bbox_xywh.append(row[2:6])\n",
    "    #now bring them in the right order of the frames for sure:\n",
    "    order_to_follow = np.argsort(frame_nr)\n",
    "    frame_nr = [frame_nr[i] for i in order_to_follow]\n",
    "    id_nr = [id_nr[i] for i in order_to_follow]\n",
    "    bbox_xywh = [bbox_xywh[i] for i in order_to_follow]\n",
    "    class_name = [class_name[i] for i in order_to_follow]\n",
    "    return {\"frame_name\": frame_nr, \"id_nr\": id_nr, \n",
    "            \"bbox_xywh\": bbox_xywh, \"class_name\": class_name}\n",
    "\n",
    "def dict_to_file(path, dict_to_write):\n",
    "    \"\"\"\n",
    "    Write a txt file with all the bboxes for the given dictionary (in the MOTChallenge format)\n",
    "\n",
    "    path: path to write the file\n",
    "    mot_dict: dictionary with all the information (coming from the function above)\n",
    "    \"\"\"\n",
    "    frame_nr = dict_to_write[\"frame_name\"]\n",
    "    id_nr = dict_to_write[\"id_nr\"]\n",
    "    bbox_xywh = dict_to_write[\"bbox_xywh\"]\n",
    "    confidence_score = dict_to_write[\"confidence_score\"]\n",
    "    with open(path, \"w\") as f:\n",
    "        for i in range(len(frame_nr)):\n",
    "            row = [str(frame_nr[i]+1), str(int(id_nr[i])), *[str(round(x, 2)) for x in bbox_xywh[i]], str(round(confidence_score[i], 2)),str(1),str(1)]\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/usr/users/vogg/macaque_videos_eval/\"\n",
    "videos = os.listdir(base_path)\n",
    "videos = [vid for vid in videos if re.search(\"vid_\", vid)]\n",
    "for video in videos:\n",
    "    #seqLength = len(os.listdir(os.path.join(base_path, video, \"labels_with_ids\")))\n",
    "    seqLength = float('-inf')\n",
    "    with open(os.path.join(base_path, video, \"gt\", \"gt.txt\"), 'r') as file:\n",
    "        for line in file:\n",
    "            first_column = int(line.split(',')[0])\n",
    "            seqLength = max(seqLength, first_column)\n",
    "\n",
    "    with open(os.path.join(base_path, video, \"seqinfo.ini\"), \"w\") as to_write:\n",
    "        to_write.write(\"[Sequence]\\n\")\n",
    "        to_write.write(\"; name=MOT16-01\\n\")\n",
    "        to_write.write(f\"; imDir={video}/images\\n\")\n",
    "        to_write.write(\"frameRate=30\\n\")\n",
    "        to_write.write(f\"seqLength={seqLength}\\n\")\n",
    "        to_write.write(\"imWidth=1920\\n\")\n",
    "        to_write.write(\"imHeight=1080\\n\")\n",
    "        to_write.write(\"imExt=.jpg\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for video in videos:\n",
    "    infos = gt_files_to_dict(os.path.join(base_path, video, \"labels_with_ids\"), scale_size = (1920, 1080))\n",
    "    print(video)\n",
    "    infos[\"confidence_score\"] = [1 for _ in infos[\"id_nr\"]]\n",
    "    dict_to_file(os.path.join(base_path, video, \"gt.txt\"), infos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where are the both datasets/ where is TrackEval located\n",
    "base_path_gt = \"/usr/users/vogg/macaque_videos_eval\"\n",
    "base_path_predictions = \"/usr/users/vogg/monkey-tracking-in-the-wild/videos/lemurs/\"\n",
    "base_path_TrackEval = \"/usr/users/vogg/monkey-tracking-in-the-wild/TrackEval\"\n",
    "experiment_name = \"lemur_buffered\" \n",
    "name_in_videos = \"Eval\" # some string that all videos have in common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file infrastructure for ground truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_TrackEval_gt = os.path.join(base_path_TrackEval, \"data\", \"gt\")\n",
    "base_path_gt_dataset = os.path.join(base_path_TrackEval_gt, experiment_name)\n",
    "    \n",
    "#create the folder structure and assume that mot annotation for macaque video is already created with the above cells\n",
    "if not os.path.exists(base_path_gt_dataset):\n",
    "    os.makedirs(base_path_gt_dataset)\n",
    "\n",
    "\n",
    "#copy groundtruth\n",
    "seq_names = [seq_name for seq_name in os.listdir(base_path_gt) if re.search(name_in_videos,seq_name )]\n",
    "\n",
    "# Copy the ground truth files for each sequence to the base_path_gt directory\n",
    "for seq_name in seq_names:\n",
    "    # Get the full path to the ground truth file\n",
    "    gt_file = os.path.join(base_path_gt, seq_name, \"gt\", \"gt.txt\")\n",
    "    info_file = os.path.join(base_path_gt, seq_name, \"seqinfo.ini\")\n",
    "    \n",
    "    # Create the directory for the sequence in base_path_gt if it doesn't exist\n",
    "    seq_dir = os.path.join(base_path_gt_dataset, seq_name,\"gt\")\n",
    "    if not os.path.exists(seq_dir):\n",
    "        os.makedirs(seq_dir)\n",
    "    \n",
    "    # Copy the ground truth file to the sequence directory in base_path_gt\n",
    "    shutil.copy(gt_file, seq_dir)\n",
    "    shutil.copy(info_file, os.path.dirname(seq_dir))\n",
    "\n",
    "# create seqnames\n",
    "seqnames_path = os.path.join(os.path.dirname(base_path_gt_dataset),\"seqmaps\")\n",
    "if not os.path.exists(seqnames_path):\n",
    "    os.makedirs(seqnames_path)\n",
    "\n",
    "# for some reason it often doesn't work on the first try, run this cell twice or several times\n",
    "    #'SPLIT_TO_EVAL': 'all'\n",
    "\n",
    "with open(os.path.join(seqnames_path, experiment_name+\".txt\"), \"w\") as seqnames:\n",
    "    seqnames.write(\"name\\n\")\n",
    "    for seq_name in seq_names:\n",
    "        seqnames.write(seq_name+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracker_name = \"macaquepose_1_150\"\n",
    "\n",
    "models = ['nopretrain']\n",
    "seeds = ['1','2','3']\n",
    "epochs = list(range(10, 251, 10))\n",
    "tracker_names = [\"macaques_\" + model + \"_\" + str(epoch) for model in models for epoch in epochs]\n",
    "\n",
    "tracker_names = [\"proportion_\" + str(i) + \"_doublekalman\" for i in [0, 0.2, 0.4, 0.6, 0.8, 1]]\n",
    "\n",
    "for tracker_name in tracker_names:\n",
    "\n",
    "    \n",
    "    base_path_trackers = os.path.join(base_path_TrackEval, \"data\", \"trackers\")\n",
    "\n",
    "    base_path_tracker = os.path.join(base_path_trackers, experiment_name, tracker_name, \"data\")\n",
    "    \n",
    "\n",
    "    if not os.path.exists(os.path.join(base_path_trackers, experiment_name, tracker_name, \"data\")):\n",
    "        os.makedirs(base_path_tracker)\n",
    "\n",
    "\n",
    "    #copy tracker results\n",
    "\n",
    "    seq_names = [seq_name for seq_name in os.listdir(base_path_predictions) if re.search(name_in_videos,seq_name )]\n",
    "    seq_dir = os.path.join(base_path_tracker)\n",
    "\n",
    "    for seq_name in seq_names:\n",
    "        # Get the full path to the ground truth file\n",
    "        #print(os.path.join(base_path_macaque_results, seq_name, tracker_name, \"results.txt\"))\n",
    "        det_file = os.path.join(base_path_predictions, seq_name, tracker_name, \"results.txt\")\n",
    "\n",
    "\n",
    "        # in case that there are several classes, we multiply each object by 100 * class_number to prevent double IDs\n",
    "        with open(det_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Process each line\n",
    "        for i, line in enumerate(lines):\n",
    "            # Split the line into elements\n",
    "            elements = line.strip().split(\", \")\n",
    "\n",
    "            # Perform the desired calculations\n",
    "            second_element = int(elements[1])\n",
    "            last_element = int(elements[-1])\n",
    "            updated_value = second_element + last_element * 100\n",
    "\n",
    "            # Update the line with the new value\n",
    "            elements[1] = str(updated_value)\n",
    "            updated_line = ','.join(elements)+\"\\n\"\n",
    "\n",
    "            # Update the list of lines\n",
    "            lines[i] = updated_line\n",
    "\n",
    "        # Write the updated lines back to the file\n",
    "        with open(os.path.join(seq_dir, seq_name + \".txt\"), 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "60ced420ad4e86a519f02723719197983a7bc8a476883984e4cadb85097aad83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
