{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>track_id</th>\n",
       "      <th>individual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>Her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e1_c4_14_24360_26100.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1_c4_14_24360_26100.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>Flo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video  track_id individual\n",
       "0  e1_c4_11_19140_20880.txt         1        Red\n",
       "1  e1_c4_11_19140_20880.txt         6        Her\n",
       "2  e1_c4_11_19140_20880.txt         8        Gen\n",
       "3  e1_c4_14_24360_26100.txt         1        Gen\n",
       "4  e1_c4_14_24360_26100.txt         3        Flo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../Labelling/Lemurs/LemurID_video_eval/groundtruth.csv\", sep = \";\")\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['additional1_roi_20',\n",
       " 'additional1_roi_30',\n",
       " 'additional1_roi_40',\n",
       " 'additional1_roi_50',\n",
       " 'base_roi_20',\n",
       " 'base_roi_30',\n",
       " 'base_roi_40',\n",
       " 'base_roi_50',\n",
       " 'cleaned1_roi_20',\n",
       " 'cleaned1_roi_30',\n",
       " 'cleaned1_roi_40',\n",
       " 'cleaned1_roi_50',\n",
       " 'cleaned1_squareroi_08_1_20',\n",
       " 'cleaned1_squareroi_08_1_30',\n",
       " 'cleaned1_squareroi_08_1_40',\n",
       " 'cleaned1_squareroi_08_1_50',\n",
       " 'cleaned1_squareroi_08_1_move20_20',\n",
       " 'cleaned1_squareroi_08_1_move20_30',\n",
       " 'cleaned1_squareroi_08_1_move20_40',\n",
       " 'cleaned1_squareroi_08_1_move20_50',\n",
       " 'cleaned1_squareroi_20',\n",
       " 'cleaned1_squareroi_30',\n",
       " 'cleaned1_squareroi_40',\n",
       " 'cleaned1_squareroi_50',\n",
       " 'cleaned1_squareroi_move20_20',\n",
       " 'cleaned1_squareroi_move20_30',\n",
       " 'cleaned1_squareroi_move20_40',\n",
       " 'cleaned1_squareroi_move20_50']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_validation = \"../videos/lemur_id_hyperparams/\"\n",
    "folder_list = sorted([elem for elem in os.listdir(path_to_validation) if not elem.startswith(\".\")])\n",
    "folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional1_roi_20 \tAccuracy: 0.6304347826086957\n",
      "additional1_roi_30 \tAccuracy: 0.6630434782608695\n",
      "additional1_roi_40 \tAccuracy: 0.6086956521739131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for experiment in folder_list:\n",
    "    video_list = os.listdir(os.path.join(path_to_validation, experiment))\n",
    "\n",
    "    prediction_df = pd.DataFrame(columns = ['video', 'track_id', 'prediction', 'track_length'])\n",
    "\n",
    "    for video_name in video_list:\n",
    "        \n",
    "        if video_name.endswith(\".txt\") and \"opt\" not in video_name:\n",
    "            df = pd.read_csv(os.path.join(path_to_validation,experiment,video_name), header=None)\n",
    "\n",
    "            df.columns = [\"frame\", \"track_id\", \"V3\", \"V4\", \"V5\", \"V6\", \"conf\", \"class\", \"Cha\", \"Flo\", \"Gen\", \"Geo\", \"Her\", \"Rab\", \"Red\", \"Uns\", \"max\", \"ID\"]\n",
    "            df['max'] = df[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max(axis=1)\n",
    "\n",
    "            filtered_df = df[df['class'] == 0]\n",
    "\n",
    "            # Group by track and calculate various statistics\n",
    "            result_df = pd.DataFrame()\n",
    "            result_df['track_id'] = filtered_df['track_id'].unique()\n",
    "\n",
    "            # Calculate the individual with the highest average probability across the track\n",
    "            result_df['highest_avg_individual'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].mean().idxmax(axis=1).values\n",
    "            result_df['highest_avg_probability'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].mean().max(axis=1).values\n",
    "\n",
    "            # Calculate the individual with the single highest probability value across the track\n",
    "            result_df['single_highest_individual'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max().idxmax(axis=1).values\n",
    "            result_df['single_highest_probability'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max().max(axis=1).values\n",
    "\n",
    "            # Calculate the individual with the highest number of times getting a probability value over 0.8 within the track\n",
    "            counts_over_thres = filtered_df[filtered_df['max'] > 0.8].groupby('track_id').apply(lambda x: x[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].idxmax(axis=1).value_counts().reset_index().rename(columns={'index': 'individual', 0: 'count'}) if not x.empty else pd.DataFrame({'individual': ['None'], 'count': [0]}))\n",
    "            if len(counts_over_thres)>0:\n",
    "                counts_over_thres = counts_over_thres.reset_index(level=1, drop = True)\n",
    "                counts_over_thres = counts_over_thres.sort_values(by='count', ascending=False).groupby('track_id').first()\n",
    "\n",
    "                # Merge with result_df using an outer join\n",
    "                result_df = pd.merge(result_df, counts_over_thres, on='track_id', how='outer')\n",
    "\n",
    "            else:\n",
    "                result_df['count'] = 0\n",
    "                result_df['individual']= \"\"\n",
    "\n",
    "            # Add total length of the track\n",
    "            result_df['track_length'] = filtered_df.groupby('track_id').size().values\n",
    "\n",
    "            #print(result_df)\n",
    "\n",
    "            thresholds = {'highest_avg_probability': 0.1, 'single_highest_probability': 0.8, 'count': 1}\n",
    "\n",
    "            value_cols = ['highest_avg_probability', 'single_highest_probability', 'count']\n",
    "            name_cols = ['highest_avg_individual', 'single_highest_individual', 'individual']\n",
    "\n",
    "            values_df = result_df[value_cols].ge(pd.Series(thresholds))\n",
    "            names_df=result_df[name_cols].fillna('').rename(columns={'highest_avg_individual': 'highest_avg_probability', 'single_highest_individual': 'single_highest_probability', 'individual': 'count'})\n",
    "\n",
    "            #median of all 3\n",
    "            result_df['prediction'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\").apply(lambda row: row.mode().iloc[0], axis = 1)\n",
    "\n",
    "            #only highest \n",
    "            result_df['prediction_count'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['count']\n",
    "            result_df['prediction_singlehighest'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['single_highest_probability']\n",
    "            result_df['prediction_avghighest'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['highest_avg_probability']\n",
    "            result_df['video'] = video_name\n",
    "            #print(result_df[['video', 'track_id', 'final']])\n",
    "            prediction_df = pd.concat([prediction_df, result_df[['video', 'track_id', 'prediction', 'track_length']].fillna(\"Uns\")], ignore_index=True)\n",
    "        \n",
    "\n",
    "    names_df.where(values_df, \"\").replace(\"\", \"Uns\")\n",
    "\n",
    "    final_df = pd.merge(gt, prediction_df, on =['video', 'track_id'], how = \"left\")\n",
    "    classes = sorted(set(final_df['individual']).union(final_df['prediction']))\n",
    "    cha = False\n",
    "    if \"Cha\" in classes:\n",
    "        classes.remove(\"Cha\")\n",
    "        cha = True\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = pd.crosstab(final_df['individual'], final_df['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    if cha:\n",
    "        conf_matrix[\"Uns\"] = conf_matrix[\"Uns\"] + conf_matrix[\"Cha\"]\n",
    "\n",
    "        # Drop the \"Cha\" column\n",
    "        conf_matrix.drop(columns=[\"Cha\"], inplace=True)\n",
    "\n",
    "\n",
    "    missing_classes = set(classes) - set(conf_matrix.columns)\n",
    "    for missing_class in missing_classes:\n",
    "        conf_matrix[missing_class] = 0\n",
    "\n",
    "    # Sort the columns and index to maintain order\n",
    "    conf_matrix = conf_matrix[sorted(set(conf_matrix.columns))].sort_index()\n",
    "\n",
    "\n",
    "    accuracy = np.diag(conf_matrix).sum() / conf_matrix.values.sum()\n",
    "    print(experiment, \"\\tAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6304347826086957\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mktrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
