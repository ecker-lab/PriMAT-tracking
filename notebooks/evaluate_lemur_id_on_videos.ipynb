{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>track_id</th>\n",
       "      <th>individual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>Her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1_c4_11_19140_20880.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e1_c4_14_24360_26100.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1_c4_14_24360_26100.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>Flo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      video  track_id individual\n",
       "0  e1_c4_11_19140_20880.txt         1        Red\n",
       "1  e1_c4_11_19140_20880.txt         6        Her\n",
       "2  e1_c4_11_19140_20880.txt         8        Gen\n",
       "3  e1_c4_14_24360_26100.txt         1        Gen\n",
       "4  e1_c4_14_24360_26100.txt         3        Flo"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = pd.read_csv(\"../../Labelling/Lemurs/LemurID_video_eval/groundtruth.csv\", sep = \";\")\n",
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_validation = \"../videos/lemur_id_validation_batch/cleaned1\"\n",
    "path_to_validation = \"../videos/lemur_ids_head/\"\n",
    "folder_list = sorted([elem for elem in os.listdir(path_to_validation) if not elem.startswith(\".\")])\n",
    "\n",
    "folder_list = ['model_'+str(i) for i in range(22, 23)]\n",
    "folder_list = ['model_32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_32 \tAccuracy: 0.42391304347826086\n"
     ]
    }
   ],
   "source": [
    "def count_over_thres(x, thres = 0.3):\n",
    "    if not x.empty:\n",
    "        counts = x[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']][x['max'] > thres].idxmax(axis=1).value_counts()\n",
    "        return counts.reset_index().rename(columns={'index': 'individual', 0: 'count'})\n",
    "    else:\n",
    "        return pd.DataFrame({'individual': ['None'], 'count': [0]})\n",
    "\n",
    "\n",
    "\n",
    "for experiment in folder_list:\n",
    "    video_list = os.listdir(os.path.join(path_to_validation, experiment))\n",
    "    video_list = [video for video in video_list if \".txt\" in video]\n",
    "\n",
    "    prediction_df = pd.DataFrame(columns = ['video', 'track_id', 'prediction', 'track_length'])\n",
    "\n",
    "    for video_name in video_list:\n",
    "        \n",
    "        if video_name.endswith(\".txt\") and \"opt\" not in video_name:\n",
    "            df = pd.read_csv(os.path.join(path_to_validation,experiment,video_name), header=None)\n",
    "\n",
    "            df.columns = [\"frame\", \"track_id\", \"V3\", \"V4\", \"V5\", \"V6\", \"conf\", \"class\", \"Cha\", \"Flo\", \"Gen\", \"Geo\", \"Her\", \"Rab\", \"Red\", \"Uns\", \"ID\"]\n",
    "            df['max'] = df[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max(axis=1)\n",
    "\n",
    "            filtered_df = df[df['class'] == 0]\n",
    "\n",
    "            # Group by track and calculate various statistics\n",
    "            result_df = pd.DataFrame()\n",
    "            result_df['track_id'] = filtered_df['track_id'].unique()\n",
    "\n",
    "            # Calculate the individual with the highest average probability across the track\n",
    "            result_df['highest_avg_individual'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].mean().idxmax(axis=1).values\n",
    "            result_df['highest_avg_probability'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].mean().max(axis=1).values\n",
    "\n",
    "            # Calculate the individual with the single highest probability value across the track\n",
    "            result_df['single_highest_individual'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max().idxmax(axis=1).values\n",
    "            result_df['single_highest_probability'] = filtered_df.groupby('track_id')[['Cha', 'Flo', 'Gen', 'Geo', 'Her', 'Rab', 'Red']].max().max(axis=1).values\n",
    "\n",
    "            # Calculate the individual with the highest number of times getting a probability value over 0.8 within the track\n",
    "            counts_over_thres = filtered_df[filtered_df['max'] > 0.3].groupby('track_id').apply(count_over_thres, thres = 0.3)\n",
    "            counts_over_thres2 = filtered_df[filtered_df['max'] > 0.9].groupby('track_id').apply(count_over_thres, thres = 0.8)\n",
    "\n",
    "            \n",
    "            if len(counts_over_thres)>0:\n",
    "                counts_over_thres = counts_over_thres.reset_index(level=1, drop = True)\n",
    "                if len(counts_over_thres2)>0:\n",
    "                    counts_over_thres2 = counts_over_thres2.reset_index(level=1, drop = True)\n",
    "                    merged_df = counts_over_thres.merge(counts_over_thres2, on=['track_id', 'individual'], how='left', suffixes=('', '_Frame2'))\n",
    "                    merged_df['count'] = merged_df['count'].fillna(0) + merged_df['count_Frame2'].fillna(0) * 100\n",
    "                    merged_df.drop(columns=['count_Frame2'], inplace=True)\n",
    "                    merged_df.reset_index(inplace=True)\n",
    "                    counts_over_thres = merged_df\n",
    "                    \n",
    "                counts_over_thres = counts_over_thres.sort_values(by='count', ascending=False).groupby('track_id').first()\n",
    "\n",
    "\n",
    "\n",
    "                # Merge with result_df using an outer join\n",
    "                result_df = pd.merge(result_df, counts_over_thres, on='track_id', how='outer')\n",
    "\n",
    "            else:\n",
    "                result_df['count'] = 0\n",
    "                result_df['individual']= \"\"\n",
    "\n",
    "            # Add total length of the track\n",
    "            result_df['track_length'] = filtered_df.groupby('track_id').size().values\n",
    "\n",
    "            #print(result_df)\n",
    "\n",
    "            thresholds = {'highest_avg_probability': 0.1, 'single_highest_probability': 0.8, 'count': 1}\n",
    "\n",
    "            value_cols = ['highest_avg_probability', 'single_highest_probability', 'count']\n",
    "            name_cols = ['highest_avg_individual', 'single_highest_individual', 'individual']\n",
    "\n",
    "            values_df = result_df[value_cols].ge(pd.Series(thresholds))\n",
    "            names_df=result_df[name_cols].fillna('').rename(columns={'highest_avg_individual': 'highest_avg_probability', 'single_highest_individual': 'single_highest_probability', 'individual': 'count'})\n",
    "\n",
    "            #median of all 3\n",
    "            result_df['prediction_median'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\").apply(lambda row: row.mode().iloc[0], axis = 1)\n",
    "\n",
    "            #only highest \n",
    "            result_df['prediction'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['count']\n",
    "            result_df['prediction_singlehighest'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['single_highest_probability']\n",
    "            result_df['prediction_avghighest'] =names_df.where(values_df, \"\").replace(\"\", \"Uns\")['highest_avg_probability']\n",
    "            result_df['video'] = video_name\n",
    "            #print(result_df[['video', 'track_id', 'final']])\n",
    "            prediction_df = pd.concat([prediction_df, result_df[['video', 'track_id', 'prediction', 'track_length']].fillna(\"Uns\")], ignore_index=True)\n",
    "        \n",
    "\n",
    "    names_df.where(values_df, \"\").replace(\"\", \"Uns\")\n",
    "\n",
    "    final_df = pd.merge(gt, prediction_df, on =['video', 'track_id'], how = \"left\")\n",
    "    classes = sorted(set(final_df['individual']))#.union(final_df['prediction']))\n",
    "    cha = False\n",
    "    if \"Cha\" in classes:\n",
    "        classes.remove(\"Cha\")\n",
    "        cha = True\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = pd.crosstab(final_df['individual'], final_df['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    if cha:\n",
    "        conf_matrix[\"Uns\"] = conf_matrix[\"Uns\"] + conf_matrix[\"Cha\"]\n",
    "\n",
    "        # Drop the \"Cha\" column\n",
    "        conf_matrix.drop(columns=[\"Cha\"], inplace=True)\n",
    "\n",
    "\n",
    "    missing_classes = set(classes) - set(conf_matrix.columns)\n",
    "    for missing_class in missing_classes:\n",
    "        conf_matrix[missing_class] = 0\n",
    "\n",
    "    # Sort the columns and index to maintain order\n",
    "    conf_matrix = conf_matrix[sorted(set(conf_matrix.columns))].sort_index()\n",
    "\n",
    "\n",
    "    accuracy = np.diag(conf_matrix).sum() / conf_matrix.values.sum()\n",
    "    print(experiment, \"\\tAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Flo</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Geo</th>\n",
       "      <th>Her</th>\n",
       "      <th>Rab</th>\n",
       "      <th>Red</th>\n",
       "      <th>Uns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Flo</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gen</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Her</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rab</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Flo  Gen  Geo  Her  Rab  Red  Uns\n",
       "Actual                                      \n",
       "Flo          1    1    2    0    0    0    0\n",
       "Gen          1    8    1    0    3    3    0\n",
       "Geo          0    1   13    8    0    0    0\n",
       "Her          0    1   10    7    1    0    0\n",
       "Rab          0    0    1    2    4    1    1\n",
       "Red          1    5    4    3    3    6    0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(conf_matrix).sum()\n",
    "conf_matrix.values.sum()\n",
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mktrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
