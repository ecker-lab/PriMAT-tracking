{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOTA evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets \n",
    "\n",
    "In this script, we are mainly moving data into the right directory and format, for HOTA evaluation. Unfortunately this is currently only possible within the [TrackEval](https://github.com/JonathonLuiten/TrackEval/) package.\n",
    "\n",
    "To run the script without modifications the data needs to be in the following structure - otherwise it was to be adapted.\n",
    "\n",
    "gt_folder \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-------Vid1 \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----labels_with_ids \\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------frame_000000.txt\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------frame_000001.txt\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------Vid2...\\\n",
    "\\\n",
    "\\\n",
    "pred_folder\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------Vid1\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------model1\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------results.txt\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------model2\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------results.txt\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|------Vid2...\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where are the both datasets/ where is TrackEval located\n",
    "animal = \"lemur\" # or \"lemur\"\n",
    "\n",
    "base_path_gt = \"/path/to/gt/\"+animal+\"_videos_eval/\"\n",
    "base_path_predictions = \"/path/to/predictions/\"\n",
    "base_path_TrackEval = \"/path/to/folder/TrackEval\"\n",
    "experiment_name = animal+\"_tracking_3seeds\" \n",
    "name_in_videos =  \"Eval\\d+\" if animal==\"lemur\" else \"vid_\" # some string that all videos have in common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt_files_to_dict(folder_path, scale_size = (1920, 1080)):\n",
    "    '''\n",
    "    input: path to a video, to the folder which contains the label files (in the format that there is \n",
    "    one label file per frame)\n",
    "    output: dictionary containing all the frames and bboxes\n",
    "    '''\n",
    "    width, height = scale_size\n",
    "    data_names = os.listdir(folder_path)\n",
    "    data_names = [name for name in data_names if re.search(\".txt\",name)]\n",
    "    frame_nr = []\n",
    "    class_name = []\n",
    "    id_nr = []\n",
    "    bbox_xywh = []\n",
    "    for data_name in data_names:\n",
    "        maca_data = open(os.path.join(folder_path,data_name)).read().strip().split(\"\\n\")\n",
    "        if maca_data == [\"\"]:\n",
    "            continue\n",
    "        maca_data = [[float(nr) for nr in row.strip().split(\" \")] for row in maca_data]\n",
    "        frame_name = data_name.split(\".\")[0]\n",
    "        #-1 that mot also starts at 0\n",
    "        frame_nr_to_append = int(re.findall(\"[0-9]+\",frame_name)[0])\n",
    "        for row in maca_data:\n",
    "            frame_nr.append(frame_nr_to_append)\n",
    "            class_name.append(row[0])\n",
    "            id_nr.append(row[1])\n",
    "            #to upper left corner from middle \n",
    "            row[2] = (float(row[2]) - float(row[4])/2) * width\n",
    "            row[3] = (float(row[3]) - float(row[5])/2) * height\n",
    "            row[4] = float(row[4]) * width\n",
    "            row[5] = float(row[5]) * height\n",
    "            row[2:6] = [round(x,2) for x in row[2:6]]\n",
    "            bbox_xywh.append(row[2:6])\n",
    "    #now bring them in the right order of the frames for sure:\n",
    "    order_to_follow = np.argsort(frame_nr)\n",
    "    frame_nr = [frame_nr[i] for i in order_to_follow]\n",
    "    id_nr = [id_nr[i] for i in order_to_follow]\n",
    "    bbox_xywh = [bbox_xywh[i] for i in order_to_follow]\n",
    "    class_name = [class_name[i] for i in order_to_follow]\n",
    "    return {\"frame_name\": frame_nr, \"id_nr\": id_nr, \n",
    "            \"bbox_xywh\": bbox_xywh, \"class_name\": class_name}\n",
    "\n",
    "def dict_to_file(path, dict_to_write):\n",
    "    \"\"\"\n",
    "    Write a txt file with all the bboxes for the given dictionary (in the MOTChallenge format)\n",
    "\n",
    "    path: path to write the file\n",
    "    mot_dict: dictionary with all the information (coming from the function above)\n",
    "    \"\"\"\n",
    "    frame_nr = dict_to_write[\"frame_name\"]\n",
    "    id_nr = dict_to_write[\"id_nr\"]\n",
    "    bbox_xywh = dict_to_write[\"bbox_xywh\"]\n",
    "    confidence_score = dict_to_write[\"confidence_score\"]\n",
    "    with open(path, \"w\") as f:\n",
    "        for i in range(len(frame_nr)):\n",
    "            row = [str(frame_nr[i]+1), str(int(id_nr[i])), *[str(round(x, 2)) for x in bbox_xywh[i]], str(round(confidence_score[i], 2)),str(1),str(1)]\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "videos = os.listdir(base_path_gt)\n",
    "videos = [vid for vid in videos if re.search(name_in_videos, vid)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval19\n",
      "Eval9\n",
      "Eval11\n",
      "Eval15\n",
      "Eval5\n",
      "Eval23\n",
      "Eval2\n",
      "Eval12\n",
      "Eval16\n",
      "Eval6\n",
      "Eval20\n",
      "Eval7\n",
      "Eval21\n",
      "Eval17\n",
      "Eval13\n",
      "Eval3\n",
      "Eval8\n",
      "Eval18\n",
      "Eval4\n",
      "Eval22\n",
      "Eval14\n",
      "Eval10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for video in videos:\n",
    "    infos = gt_files_to_dict(os.path.join(base_path_gt, video, \"labels_with_ids\"), scale_size = (1920, 1080))\n",
    "    print(video)\n",
    "    infos[\"confidence_score\"] = [1 for _ in infos[\"id_nr\"]]\n",
    "    if not os.path.exists(os.path.join(base_path_gt, video, \"gt\")):\n",
    "        os.makedirs(os.path.join(base_path_gt, video, \"gt\"))\n",
    "    dict_to_file(os.path.join(base_path_gt, video, \"gt\", \"gt.txt\"), infos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for video in videos:\n",
    "    #seqLength = len(os.listdir(os.path.join(base_path, video, \"labels_with_ids\")))\n",
    "    seqLength = float('-inf')\n",
    "    with open(os.path.join(base_path_gt, video, \"gt\", \"gt.txt\"), 'r') as file:\n",
    "        for line in file:\n",
    "            first_column = int(line.split(',')[0])\n",
    "            seqLength = max(seqLength, first_column)\n",
    "\n",
    "    with open(os.path.join(base_path_gt, video, \"seqinfo.ini\"), \"w\") as to_write:\n",
    "        to_write.write(\"[Sequence]\\n\")\n",
    "        to_write.write(\"; name=MOT16-01\\n\")\n",
    "        to_write.write(f\"; imDir={video}/images\\n\")\n",
    "        to_write.write(\"frameRate=30\\n\")\n",
    "        to_write.write(f\"seqLength={seqLength}\\n\")\n",
    "        to_write.write(\"imWidth=1920\\n\")\n",
    "        to_write.write(\"imHeight=1080\\n\")\n",
    "        to_write.write(\"imExt=.jpg\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_TrackEval_gt = os.path.join(base_path_TrackEval, \"data\", \"gt\")\n",
    "base_path_gt_dataset = os.path.join(base_path_TrackEval_gt, experiment_name)\n",
    "    \n",
    "#create the folder structure and assume that mot annotation for macaque video is already created with the above cells\n",
    "if not os.path.exists(base_path_gt_dataset):\n",
    "    os.makedirs(base_path_gt_dataset)\n",
    "\n",
    "\n",
    "#copy groundtruth\n",
    "seq_names = [seq_name for seq_name in os.listdir(base_path_gt) if re.search(name_in_videos,seq_name )]\n",
    "\n",
    "# Copy the ground truth files for each sequence to the base_path_gt directory\n",
    "for seq_name in seq_names:\n",
    "    # Get the full path to the ground truth file\n",
    "    gt_file = os.path.join(base_path_gt, seq_name, \"gt\", \"gt.txt\")\n",
    "    info_file = os.path.join(base_path_gt, seq_name, \"seqinfo.ini\")\n",
    "    \n",
    "    # Create the directory for the sequence in base_path_gt if it doesn't exist\n",
    "    seq_dir = os.path.join(base_path_gt_dataset, seq_name,\"gt\")\n",
    "    if not os.path.exists(seq_dir):\n",
    "        os.makedirs(seq_dir)\n",
    "    \n",
    "    # Copy the ground truth file to the sequence directory in base_path_gt\n",
    "    shutil.copy(gt_file, seq_dir)\n",
    "    shutil.copy(info_file, os.path.dirname(seq_dir))\n",
    "\n",
    "# create seqnames\n",
    "seqnames_path = os.path.join(os.path.dirname(base_path_gt_dataset),\"seqmaps\")\n",
    "if not os.path.exists(seqnames_path):\n",
    "    os.makedirs(seqnames_path)\n",
    "\n",
    "# for some reason it often doesn't work on the first try, run this cell twice or several times\n",
    "    #'SPLIT_TO_EVAL': 'all'\n",
    "\n",
    "with open(os.path.join(seqnames_path, experiment_name+\".txt\"), \"w\") as seqnames:\n",
    "    seqnames.write(\"name\\n\")\n",
    "    for seq_name in seq_names:\n",
    "        seqnames.write(seq_name+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracker_name = \"macaquepose_1_150\"\n",
    "\n",
    "models = ['model_50', 'model_100', 'model_150', 'model_200']\n",
    "confs = ['0.01', '0.02', '0.04', '0.1', '0.2', '0.4']\n",
    "dets = ['0.4', '0.5', '0.6']\n",
    "assocs = ['0.7', '0.8', '0.9']\n",
    "news = ['0.5', '0.6', '0.7', '0.8']\n",
    "propious = ['0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1']\n",
    "datasets = ['imagenet', 'macaquecp', 'nopretrain', 'macaquecpw']\n",
    "lr = ['_5e-5']\n",
    "seeds = ['1','2','3']\n",
    "epochs = list(range(10, 201, 10))\n",
    "methods = ['singlekalman', 'doublekalman']\n",
    "\n",
    "#tracker_names = [\"macaques_\" + model + \"_\" + str(epoch) for model in models for epoch in epochs]\n",
    "#tracker_names = [animal+\"s_\"  + dataset + \"_\" + str(i) + l for i in range(10, 201,10) for dataset in datasets for l in lr] #lemur_tracking\n",
    "tracker_names = [animal+\"s_\"  + dataset + \"_\" + str(i) for i in range(1,4) for dataset in datasets] #lemur_tracking_3seeds\n",
    "#tracker_names = [animal+\"s_\"+str(iou) for iou in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]]\n",
    "#tracker_names = [animal+\"s_\" + conf + \"_\" + det + \"_\" + assoc + \"_\" + propiou + \"/\" + method for conf in confs for det in dets for assoc in assocs for propiou in propious for method in methods]\n",
    "\n",
    "#tracker_names = [animal+\"s_\" + conf + \"_\" + det + \"_\" + new +\"/singlekalman\" for conf in confs for det in dets for new in news]\n",
    "\n",
    "for tracker_name in tracker_names:\n",
    "    \n",
    "    base_path_trackers = os.path.join(base_path_TrackEval, \"data\", \"trackers\")\n",
    "    base_path_tracker = os.path.join(base_path_trackers, experiment_name, tracker_name.replace(\"/\", \"_\"), \"data\")\n",
    "    \n",
    "\n",
    "    if not os.path.exists(os.path.join(base_path_trackers, experiment_name, tracker_name.replace(\"/\", \"_\"), \"data\")):\n",
    "        os.makedirs(base_path_tracker)\n",
    "\n",
    "\n",
    "    #copy tracker results\n",
    "    #If this cannot be searched by name, you can also manually put it\n",
    "    seq_names = [seq_name for seq_name in os.listdir(os.path.join(base_path_predictions, tracker_name)) if re.search(name_in_videos, seq_name )]\n",
    "    seq_dir = os.path.join(base_path_tracker)\n",
    "\n",
    "    for seq_name in seq_names:\n",
    "        # Get the full path to the ground truth file\n",
    "        #print(os.path.join(base_path_macaque_results, seq_name, tracker_name, \"results.txt\"))\n",
    "        #det_file = os.path.join(base_path_predictions, tracker_name, seq_name, seq_name + \".txt\")\n",
    "        det_file = os.path.join(base_path_predictions, tracker_name, seq_name)\n",
    "\n",
    "        # in case that there are several classes, we multiply each object by 100 * class_number to prevent double IDs\n",
    "        with open(det_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Process each line\n",
    "        for i, line in enumerate(lines):\n",
    "            # Split the line into elements\n",
    "            elements = line.strip().split(\", \")\n",
    "\n",
    "            # Perform the desired calculations\n",
    "            second_element = int(elements[1])\n",
    "            last_element = int(elements[-1])\n",
    "            updated_value = second_element + last_element * 100\n",
    "\n",
    "            # Update the line with the new value\n",
    "            elements[1] = str(updated_value)\n",
    "            updated_line = ','.join(elements)+\"\\n\"\n",
    "\n",
    "            # Update the list of lines\n",
    "            lines[i] = updated_line\n",
    "\n",
    "        # Write the updated lines back to the file\n",
    "        with open(os.path.join(seq_dir, seq_name), 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate results\n",
    "\n",
    "This happens after running python TrackEval/run_HOTA_evaluation.py --BENCHMARK [insert name of experiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = animal+\"_tracking_3seeds\"\n",
    "\n",
    "folder_path = \"../TrackEval/data/trackers/\"+ experiment_name\n",
    "output_file = os.path.join(folder_path,\"..\",\"..\", \"summary_\" + experiment_name + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Initialize a flag to track if the header has been written\n",
    "    header_written = False\n",
    "\n",
    "    # Iterate over the subfolders in the specified directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        dirs.sort()\n",
    "        # Look for the box_detailed.csv file in each subfolder\n",
    "        if 'macaque_summary.txt' in files:\n",
    "            file_path = os.path.join(root, 'macaque_summary.txt')\n",
    "\n",
    "            # Read the contents of the file and write them to the output CSV\n",
    "            with open(file_path, 'r') as infile:\n",
    "                reader = csv.reader(infile, delimiter=\" \")\n",
    "                header = next(reader)\n",
    "\n",
    "                # Check if the header needs to be written\n",
    "                if not header_written:\n",
    "                    header.insert(0, 'metric')\n",
    "                    writer.writerow(header)\n",
    "                    header_written = True\n",
    "\n",
    "                # Write the remaining rows\n",
    "                for row in reader:\n",
    "                    row.insert(0, str(root.split(\"/\")[-1]))\n",
    "                    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "60ced420ad4e86a519f02723719197983a7bc8a476883984e4cadb85097aad83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
